{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit Podcast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatize podcast edition as much as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ironbar.github.io/tertulia_inteligencia_artificial/como-se-hace/edicion/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://librosa.org/doc/main/generated/librosa.feature.rms.html\n",
    "- https://librosa.org/doc/main/generated/librosa.resample.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import subprocess\n",
    "import glob\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 5)\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Remove all handlers associated with the root logger\n",
    "logging.getLogger().handlers = []\n",
    "\n",
    "# Configure logging again with the desired format and level\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_tracks_volume(filepath, output_filepath=None):\n",
    "    gains, amplification = compute_gains_to_merge_audios(filepath)\n",
    "    print(f'Gains: {gains}')\n",
    "    audio, sr = merge_audios_with_gains(filepath, gains, amplification)\n",
    "    if output_filepath is None:\n",
    "        output_filepath = filepath.replace('raw_audios', 'curated_audios').replace('_alsa2', '')\n",
    "    print(f'Saving to: {output_filepath}')\n",
    "    os.makedirs(os.path.dirname(output_filepath), exist_ok=True)\n",
    "    sf.write(output_filepath, audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length = 2048\n",
    "hop_length = 512\n",
    "target_sr = 8000\n",
    "\n",
    "def compute_gains_to_merge_audios(filepath, target_sr=target_sr,\n",
    "                                  db_goal=-12.5, moving_average_window=10):\n",
    "    \"\"\"\n",
    "    db_goal=-25, moving_average_window=10 works well\n",
    "    \"\"\"\n",
    "    audios = librosa.load(filepath, sr=target_sr, mono=False)[0]\n",
    "    print(f'Loaded audio with {len(audios)} tracks and duration of {len(audios[0]) / target_sr / 60:.1f} minutes')\n",
    "    rms_values = [librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0] for y in tqdm(audios, desc='computing rms values')]\n",
    "    gains = optimize_track_gains(rms_values, db_goal)\n",
    "    amplification = get_amplification_mask_to_lower_high_volume_instants(\n",
    "        rms_values, gains, db_goal=db_goal, moving_average_window=moving_average_window)\n",
    "    return gains, amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_track_gains(rms_values, db_goal=-20, n_runs=10, factors=[0.8, 1.25, 1.5, 2]):\n",
    "    gains = [1 for _ in rms_values]\n",
    "    visualize_tracks_with_gains(rms_values, gains)\n",
    "    merge = merge_rms(rms_values, gains)\n",
    "    best_fitness = measure_fitness(merge, db_goal)\n",
    "    print(f'Initial fitness: {best_fitness:.2f}')\n",
    "\n",
    "    for _ in tqdm(range(n_runs), desc='Optimizing track gain'):\n",
    "        for factor in factors:\n",
    "            for track_idx, _ in enumerate(rms_values):\n",
    "                new_gains = gains.copy()\n",
    "                new_gains[track_idx] *= factor\n",
    "                fitness = measure_fitness(merge_rms(rms_values, new_gains), db_goal)\n",
    "                if fitness > best_fitness:\n",
    "                    gains = new_gains\n",
    "                    best_fitness = fitness\n",
    "    print(f'Final fitness: {best_fitness:.2f}')\n",
    "    visualize_tracks_with_gains(rms_values, gains)\n",
    "    visualize_merged_energy(rms_values, gains)\n",
    "    return gains\n",
    "\n",
    "def merge_rms(rms_values, gains):\n",
    "    merge = (rms_values[0]*gains[0])**2\n",
    "    for rms, gain in zip(rms_values[1:], gains[1:]):\n",
    "        merge += (rms*gain)**2\n",
    "    return np.sqrt(merge)\n",
    "\n",
    "def measure_fitness(rms, db_goal, goal_width=2):\n",
    "    lower_bound = db_goal - goal_width\n",
    "    upper_bound = db_goal + goal_width\n",
    "    rms_db = librosa.amplitude_to_db(rms)\n",
    "    fitness = (rms_db > lower_bound) & (rms_db < upper_bound)\n",
    "    return np.mean(fitness)\n",
    "\n",
    "\n",
    "def visualize_tracks_with_gains(rms_values, gains):\n",
    "    bins = np.linspace(-60, 0, 500)\n",
    "    for idx, rms in enumerate(rms_values):\n",
    "        label = f'track{idx+1} (gain={gains[idx]:.2f})'\n",
    "        plt.hist(librosa.amplitude_to_db(rms*gains[idx]), bins=bins, alpha=0.8, label=label, histtype='step', density=True)\n",
    "    plt.hist(librosa.amplitude_to_db(merge_rms(rms_values, gains)), bins=bins, alpha=0.2, label='merge', density=True)\n",
    "    plt.grid()\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()\n",
    "\n",
    "def visualize_merged_energy(rms_values, gains):\n",
    "    merge = merge_rms(rms_values, gains)\n",
    "    t = librosa.frames_to_time(range(len(merge)), sr=target_sr, hop_length=hop_length, n_fft=frame_length)\n",
    "    plt.plot(t/60, librosa.amplitude_to_db(merge))\n",
    "    plt.plot(t/60, moving_average(librosa.amplitude_to_db(merge), 30))\n",
    "    plt.title('RMS Energy')\n",
    "    plt.xlabel('Time (minutes)')\n",
    "    plt.ylabel('Energy (dB)')\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    moving_average = np.convolve(data, weights, 'valid')\n",
    "    left = window_size//2\n",
    "    right = len(data) - len(moving_average) - left\n",
    "    moving_average = np.pad(moving_average, (left, right), mode='edge')\n",
    "    return moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_audios_with_gains(filepaths, gains):\n",
    "    audio, sr = None, None\n",
    "    for filepath, gain in tqdm(zip(filepaths, gains), total=len(filepaths), desc='merging audios'):\n",
    "        ret = librosa.load(filepath, sr=None)\n",
    "        new_audio = ret[0]\n",
    "        if audio is None:\n",
    "            audio = new_audio*gain\n",
    "            sr = ret[1]\n",
    "        else:\n",
    "            audio[:len(new_audio)] += new_audio[:len(audio)]*gain\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amplification_mask_to_lower_high_volume_instants(rms_values, gains, db_goal, moving_average_window=30):\n",
    "    merge = merge_rms(rms_values, gains)\n",
    "    merge_rms_dbs = librosa.amplitude_to_db(merge)\n",
    "    modifier = np.clip(moving_average(merge_rms_dbs, moving_average_window) - db_goal, 0, None)\n",
    "    amplification = 10**(-modifier/20)\n",
    "    return amplification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_audios_with_gains(filepath, gains, amplification):\n",
    "    audios, sr = librosa.load(filepath, sr=None, mono=False)\n",
    "    audio = np.average(audios, axis=0, weights=gains)*np.sum(gains)/len(gains)\n",
    "    audio *= np.repeat(amplification, np.ceil(len(audio)/len(amplification)))[:len(audio)]\n",
    "    audio = remove_audio_saturation(audio)\n",
    "    return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_audio_saturation(audio, threshold=0.9, pool_size=4800):\n",
    "    intensity = np.abs(audio)\n",
    "    modification = np.clip(intensity/threshold, 1, None)\n",
    "    modification = block_reduce(modification, block_size=pool_size, func=np.max)\n",
    "    soften_modification = moving_average(modification, 10)\n",
    "    modification = np.maximum(modification, soften_modification)\n",
    "    plt.plot(modification)\n",
    "    modification = np.repeat(modification, pool_size)\n",
    "    audio[:len(modification)] /= modification[:len(audio)]\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compose program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_program(intro_filepath,\n",
    "                    episode_filepath,\n",
    "                    output_filepath,\n",
    "                    intro_music_filepath='/mnt/data/other/data/TERTULia/sound_library/intro_music_v5_auto.mp3',\n",
    "                    outro_music_filepath='/mnt/data/other/data/TERTULia/sound_library/outro_v5_auto.mp3',\n",
    "                    background_music_filepath='/mnt/data/other/data/TERTULia/sound_library/The lofi room_113.mp3',\n",
    "                    intro_music_start_duration=55,\n",
    "                    intro_music_high_duration=15,\n",
    "                    outro_music_high_duration=15,\n",
    "                    background_music_gain=0.5,\n",
    "                    intro_music_gain=0.5,\n",
    "                    outro_music_gain=0.5,\n",
    "                    sr=48000):\n",
    "    logging.info('Preparing program intro')\n",
    "    intro_audio = librosa.load(intro_filepath, sr=sr)[0]\n",
    "    intro_audio = np.pad(intro_audio, (sr, 0), 'constant')\n",
    "    intro_music = librosa.load(intro_music_filepath, sr=sr)[0]*intro_music_gain\n",
    "    crop_intro = intro_music_start_duration - len(intro_audio)/sr\n",
    "    assert crop_intro > 0\n",
    "    intro_music = intro_music[int(crop_intro*sr):]\n",
    "    intro_music[:len(intro_audio)] += intro_audio\n",
    "    logging.info('Adding program outro')\n",
    "    outro_music = librosa.load(outro_music_filepath, sr=sr)[0]*outro_music_gain\n",
    "    episode = librosa.load(episode_filepath, sr=sr)[0]\n",
    "    episode = np.pad(episode, (int(len(intro_audio) + intro_music_high_duration*sr), int(outro_music_high_duration*sr)), 'constant')\n",
    "    episode[:len(intro_music)] += intro_music\n",
    "    episode[-len(outro_music):] += outro_music\n",
    "    logging.info('Adding background music')\n",
    "    background_music = librosa.load(background_music_filepath, sr=sr)[0]\n",
    "    background_music = background_music[:len(episode) - len(intro_music) - len(outro_music)]\n",
    "    episode[len(intro_music):-len(outro_music)] += background_music*background_music_gain\n",
    "    logging.info(f'Saving program to {output_filepath}...')\n",
    "    sf.write(output_filepath, episode, sr)\n",
    "    logging.info('Program saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_with_ffmpeg(audio_filepath, image_filepath, video_filepath, temp_video_duration=200):\n",
    "    # create_video_command = f'ffmpeg -loop 1 -framerate 1 -i \"{image_filepath}\" -i \"{audio_filepath}\" -c:v libx264 -preset ultrafast -tune stillimage -c:a copy -pix_fmt yuv420p -shortest -threads 12 \"{video_filepath}\"'\n",
    "    # execute_command(create_video_command)\n",
    "    short_video_filepath = 'temp.mp4'\n",
    "    if os.path.exists(short_video_filepath):\n",
    "        os.remove(short_video_filepath)\n",
    "    command = f'ffmpeg -loop 1 -framerate 1 -i \"{image_filepath}\" -c:v libx264 -preset ultrafast -tune stillimage -t {temp_video_duration} -pix_fmt yuv420p \"{short_video_filepath}\"'\n",
    "    execute_command(command)\n",
    "    command = f'ffmpeg -stream_loop -1 -i \"{short_video_filepath}\" -i \"{audio_filepath}\" -c:v copy -c:a copy -shortest \"{video_filepath}\"'\n",
    "    execute_command(command)\n",
    "    os.remove(short_video_filepath)\n",
    "    return video_filepath\n",
    "\n",
    "\n",
    "def execute_command(command, verbose=True):\n",
    "    if verbose:\n",
    "        print(f'Executing command: {command}')\n",
    "        process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "        # Loop to print the output in real-time\n",
    "        for line in process.stdout:\n",
    "            print(line, end='')\n",
    "\n",
    "        # Wait for the process to complete\n",
    "        process.wait()\n",
    "    else:\n",
    "        logging.info(f'Running {command}')\n",
    "        os.system(command)\n",
    "        logging.info(f'Finished running')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_all_audios(folder):\n",
    "    filepaths = sorted(glob.glob(os.path.join(folder, 'recording*.wav')))\n",
    "    output_filepath = os.path.join(folder, f'concatenated.wav')\n",
    "    concatenate_audios(filepaths, output_filepath)\n",
    "\n",
    "def concatenate_audios(filepaths, output_filepath):\n",
    "    ret = [librosa.load(filepath, sr=None, mono=False) for filepath in tqdm(filepaths, desc='loading audios')]\n",
    "    sr = ret[0][1]\n",
    "    assert all(sr == ret[i][1] for i in range(1, len(ret)))\n",
    "    audios = np.hstack([ret[i][0] for i in range(len(ret))])\n",
    "    print(f'Writing concatenated audio to {output_filepath} with {len(audios)} tracks and {len(audios[0])/sr/60:.1f} minutes duration')\n",
    "    sf.write(output_filepath, np.transpose(audios, axes=(1, 0)), sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all audios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it makes sense to concatenate all audios before adjusting the track volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_all_audios('/mnt/data/other/data/TERTULia/episodios/temporada_3/episodio_14_mayo/raw_audios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust tracks volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many speakers in the podcast and they should have the same volume. When merging the tracks into a single one we would like to see a uniform volume level.\n",
    "\n",
    "Sometimes when a speaker speaks too little, or the signal-noise ratio is bad there can be problems. In those cases the best solution is to manually edit the file and silence the background parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjust_tracks_volume('/mnt/data/other/data/TERTULia/episodios/temporada_3/episodio_14_mayo/raw_audios/concatenated.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual revision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to `curated_audios` folder\n",
    "- Rename the audio to something like `part1_v0.wav`\n",
    "- Remove parts of the episode with fails\n",
    "- Reorder the episode if necessary (if we record the intro at the end)\n",
    "- Truncate silence, -25 dB, 1 second, 1 second (adjust the noise threshold if necessary)\n",
    "- Compressor, Threshold -20 dB, Noise Floor -60 dB, Ratio 3:1, attack time 0.2s, release time 1s\n",
    "- Save as `part1_v1.wav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record intro audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write intro for the program, and add it to the description. Giving ChatGPT the script of the program could be useful to gather ideas for the intro.\n",
    "2. Record it using `record.sh`\n",
    "3. Load with audacity and `Normalize` and apply `Compressor`\n",
    "4. Save it with the name `part1_intro.wav`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a few programs I have tried using GPT4.5 to generate the intro text, using this prompt:\n",
    "\n",
    "```\n",
    "Resume este abstract de un artículo en 2-3 líneas para una introducción de un podcast. La introducción tiene que ser muy atractiva para que el oyente sepa lo que va a escuchar en el programa y se quede. La frase final tiene que tener mucha fuerza porque luego se pone la sintonía del programa.\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/mnt/data/other/data/TERTULia/episodios_tertulia/temporada_4/grabacion_01'\n",
    "idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_program(intro_filepath=os.path.join(folder, 'curated_audios', f'part{idx}_intro.mp3'),\n",
    "                episode_filepath=os.path.join(folder, 'curated_audios', f'part{idx}_v1.mp3'),\n",
    "                output_filepath=os.path.join(folder, 'curated_audios', f'part{idx}_v2.mp3'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder called miniatures and save the miniatures there with these names: `part1_youtube.png` and `part1_ivoox.png`\n",
    "\n",
    "https://docs.google.com/presentation/d/1vtZ28nXhAE0UOhX389GVYb2JZdlFav0FtU0BLGOgFow/edit#slide=id.g2e5393793fc_0_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create a video using the audio of the program and the miniature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video_with_ffmpeg(\n",
    "    audio_filepath=os.path.join(folder, 'curated_audios', f'part{idx}_v2.mp3'),\n",
    "    image_filepath=os.path.join(folder, 'miniatures', f'part{idx}_youtube.png'),\n",
    "    video_filepath=os.path.join(folder, 'curated_audios', f'part{idx}_v2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish and gather suscribers stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google sheet](https://docs.google.com/spreadsheets/d/1rT_tqf2MN8p5VNHsaxPrNQTT-IkxjzchQKbhbH84Esw/edit?gid=2012942565#gid=2012942565)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Announce in twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- [x] Automatic search of gains to have a good merge audio\n",
    "- [x] Try with audio from other episodes\n",
    "- [x] Find a correspondence between audacity dBs and this notebook dBs. It is exactly the same. The difference is that audacity shows 2 values, the peak energy and mean energy. We are measuring mean energy.\n",
    "- [x] Add a script to compose the program\n",
    "- [x] Add a script to create the video for youtube\n",
    "- [x] Add a function to decrease volume in some parts of the audio.\n",
    "- [x] Add a function to avoid saturation of volume\n",
    "- [x] Add lofi music to the background of the episode\n",
    "- [ ] Simplify and automate paths\n",
    "- [ ] Logging\n",
    "- [ ] Reduce echo, -15dB seems to be more natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tertulia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
